# QonQrete Visual FaQtory v0.3.5-beta
[![License: AGPL v3](https://img.shields.io/badge/License-AGPL_v3-blue.svg)](LICENSE)
![Repo Views](https://komarev.com/ghpvc/?username=illdynamics-visual-faqtory&label=Repo+Views&color=blue)

![Splash](visual-faqtory.png)

```
 â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—
 â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘         â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•
 â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
 â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘         â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–„â–„ â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—  â•šâ–ˆâ–ˆâ•”â•
  â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•   â–ˆâ–ˆâ•‘   â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘
   â•šâ•â•â•â•  â•šâ•â•â•šâ•â•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•â•    â•šâ•â•     â•šâ•â•  â•šâ•â• â•šâ•â•â–€â–€â•â•    â•šâ•â•    â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•   â•šâ•â•
```

> **Automated Long-form AI Visual Generation for Music, DJ Sets & Experimental AV**

> **v0.3.5-beta** â€” Production ready, stage safe, no hand-waving. Fixed stream/longcat (true autoregressive continuation), unified macro semantics, color stability controller, TouchDesigner integration contract (no `.toe` shipped).

---

## What This Does

Visual FaQtory takes a text prompt or base image and generates hours of evolving, forward-evolving visual content. Each cycle produces a video segment that morphs into the next, creating an infinite visual journey. After all cycles complete, the pipeline automatically interpolates to 60fps and upscales to 1920Ã—1080 for cinema-smooth deliverables. Perfect for DJ sets, video installations, streams, and experimental AV.

---

## What's New in v0.3.5-beta

**âš¡ Audio Toggle â‰¤200ms** â€” Background polling thread ensures macro response within 200ms regardless of frame generation time.

**ğŸ¬ Longcat Actually Works** â€” Default runs now produce real extended output. Target duration computed from `target_seconds` â†’ `target_frames` â†’ `generate_frames Ã— max_iterations`.

**ğŸ¨ Stability Everywhere** â€” Color collapse prevention applied to all generation paths (offline, stream, Turbo).

**ğŸ“¡ VRAM Logging** â€” INFO-level estimates before each iteration. Clear warnings when safety caps hit.

**ğŸ“– No More Lies** â€” Every doc claim verified against code. TouchDesigner section states no `.toe` shipped. Longcat conditioning honesty documented.

---

## What Was New in v0.3.4-beta

**ğŸ”§ Fixed Stream/Longcat: True Autoregressive Continuation** â€” v0.3.3 Stream mode only restyled context frames. v0.3.4 uses SVD temporal diffusion to generate genuinely new frames beyond the context window. Each iteration takes the last frame, runs it through `SVD_img2vid_Conditioning`, and appends the new frames to the timeline. Stream output now actually grows every iteration and `generate_frames` controls how much.

**STREAM is offline cinematic. TURBO is live. Don't confuse them.**

**ğŸ›ï¸ Unified Macro Semantics** â€” Turbo no longer auto-deletes macro files. The contract is now deterministic: file exists = macro active. MIDI NOTE_ON creates the file, NOTE_OFF removes it. Turbo just reads. Works with any file-based trigger (scripts, OSC bridges, etc.).

**ğŸ¨ Long-Run Stability Controller** â€” New `vfaq/color_stability.py` prevents diffusion feedback collapse (the "green blob" problem). Uses CIELAB palette anchoring to the first frame, detects collapse via saturation/dominance/edge metrics, and mitigates by adjusting CFG, seed drift, and injecting micro-noise. CPU-side, <2ms per frame.

**ğŸ¥ TouchDesigner Integration Contract** â€” The `touchdesigner/` directory includes a network blueprint (`NETWORK_CONTRACT.txt`) and a Python builder (`td_setup.py`) describing the complete FX chain. Audio Device In, Analyze CHOP, Feedback loop, Displace, HUD overlay, MIDI In, OSC In. No binary `.toe` is shipped â€” you create the project in TD using the contract. TD keeps running even when AI stalls.

**ğŸ§ Audio-Reactive Finalization** â€” Explicit audio-paused state when crowd override is active. Audio failure disables the controller, never crashes the frame loop. No GPU rebuilds from audio events.
```
- Trims final video to exact audio duration
- Muxes audio into final MP4

**ğŸ”„ Stream Mode (Longcat)** â€” True autoregressive continuation:
```bash
python vfaq_cli.py run -c 20 --stream      # Enable longcat mode
```
- Cycleâ€¯N loads a short tail clip of up to `context_frames` frames from Cycleâ€¯Nâ€‘1, **extracts the last frame** of that clip and uses it as the conditioning image for temporal diffusion. The entire tail window is not fed into the model.
- Generates `generate_frames` genuinely new frames beyond the tail clip and appends them to the timeline (the tail frames themselves are not duplicated).
- Repeats until the cycle's target length is met (full autoregression).
- Configurable via the `stream` section (`context_frames`, `generate_frames`, `max_iterations`, `checkpoint`).
- **Slower and VRAMâ€‘heavy** â€” designed for offline cinematic runs, not live performances.

---

## Supported Modes

| Mode | Cycle 0 | Cycle N>0 |
|------|---------|-----------|
| `text` | text â†’ image â†’ video | video â†’ video (evolution) |
| `image` | image â†’ video (skip img gen) | video â†’ video (evolution) |
| `video` | âŒ Not valid for cycle 0 | video â†’ video (evolution) |

After cycle 0, the pipeline always chains: previous video â†’ extract frame â†’ img2img â†’ img2vid. Visual identity is **never hard-reset** between cycles.

---

## Requirements

- **Python** 3.10+
- **FFmpeg** (with h264_nvenc or libx264)
- **GPU** (for real backends; mock requires none)
- **pyyaml**, **pillow** (pip install)

---

## Quick Start

```bash
# 1. Enter directory
cd visual-faqtory-v0.3.5-beta

# 2. Install dependencies
pip install pyyaml pillow

# 3. Quick smoke test (mock backend, no GPU needed)
python quick_test.py

# 4. Run 3 cycles as a named project
python vfaq_cli.py run -n test-run -c 3 -b mock --delay 1

# 5. Check the project output
ls worqspace/qonstructions/test-run/videos/

# 6. Assemble final video
python vfaq_cli.py assemble -n test-run
```

---

## CLI Reference

```bash
# Run generation
python vfaq_cli.py run [OPTIONS]
  -n, --name NAME      Project name (stored in worqspace/qonstructions/<n>/)
  -c, --cycles N       Run N cycles (default: unlimited)
  --hours H            Target H hours of content
  -b, --backend TYPE   Override backend (mock/comfyui/diffusers/replicate)
  --delay SECONDS      Delay between cycles (default: 2)
  --fresh              Start fresh (ignore saved state)
  --match-audio        Align visual duration to audio length (v0.1.2)
  --duration SECONDS   Fixed duration mode (v0.1.2)
  --stream             Enable stream continuation mode (v0.2.0)

# TURBO Live Mode (v0.3.5-beta)
python vfaq_cli.py live [OPTIONS]
  --turbo              Enable TURBO frame generation (default)
  --fps N              Target FPS (default: from config)
  --size WxH           Resolution (e.g., 768x432)
  --crowd              Enable crowd prompt server
  --crowd-port PORT    Crowd server port (default: 7777)
  --crowd-token TOKEN  Auth token for crowd submissions

# Single test cycle
python vfaq_cli.py single [-n NAME] [--cycle N] [-b BACKEND]

# Check status
python vfaq_cli.py status [-n NAME]

# List available backends
python vfaq_cli.py backends

# Assemble all videos into final_output.mp4
python vfaq_cli.py assemble [-n NAME] [--preview]

# Clean up
python vfaq_cli.py clean [-n NAME] [--all]
```

---

## Worqspace Layout (Prompt Bundle)

```
worqspace/
â”œâ”€â”€ tasq.md                   # Base creative prompt (REQUIRED)
â”œâ”€â”€ negative_prompt.md        # What to avoid (optional)
â”œâ”€â”€ style_hints.md            # Style + evolution constraints (optional)
â”œâ”€â”€ motion_prompt.md          # Video motion intent (optional)
â”œâ”€â”€ config.yaml               # Mechanical parameters (REQUIRED)
â”œâ”€â”€ inputs/                   # Base images for image mode
â”œâ”€â”€ examples/                 # Example configs and templates
â””â”€â”€ qonstructions/            # Project output directories
```

---

## Project-Based Runs

When you use `-n <project-name>`, all outputs go into a structured project directory:

```
worqspace/qonstructions/<project-name>/
â”œâ”€â”€ briqs/                    # VisualBriq JSON state files
â”œâ”€â”€ images/                   # Generated source images
â”œâ”€â”€ videos/                   # Per-cycle MP4s + raw videos
â”‚   â”œâ”€â”€ cycle0000_raw.mp4
â”‚   â”œâ”€â”€ cycle0000_video.mp4
â”‚   â”œâ”€â”€ cycle0001_raw.mp4
â”‚   â””â”€â”€ cycle0001_video.mp4
â”œâ”€â”€ factory_state.json        # Pipeline state (resumable)
â”œâ”€â”€ config_snapshot.yaml      # Config used for this run
â”œâ”€â”€ final_output.mp4          # Stitched base master (8fps, 1024Ã—576)
â””â”€â”€ final_60fps_1080p.mp4     # Final deliverable (60fps, 1920Ã—1080)
```

If you omit `-n`, the run uses a temporary directory (`qodeyard/`). After completion, you're prompted to save it as a named project.

---

## Pipeline Flow

```
cycle generation (InstruQtor â†’ ConstruQtor â†’ InspeQtor)
  â†’ per-cycle video (passthrough or loop)
  â†’ cycle stitching (stream-copy / re-encode)
  â†’ final_output.mp4 (BASE MASTER â€” 8fps, 1024Ã—576)
  â†’ POST-STITCH FINALIZER:
       â†’ interpolate to 60fps (minterpolate MCI)
       â†’ upscale to 1920Ã—1080 (bicubic)
       â†’ encode (h264_nvenc / libx264)
  â†’ final_60fps_1080p.mp4 (FINAL DELIVERABLE)
  â†’ pipeline exit
```

---

## Config vs tasq.md (Strict Separation)

**tasq.md** = Creative intent ONLY:
- `title`, `mode`, `backend`, `input_image`/`base_image`
- Descriptive prompt text
- Negative prompt text

**config.yaml** = Mechanical truth ONLY:
- `width`, `height`, `fps`, `duration`, `steps`
- `video_frames`, `clip_seconds`, `cfg_scale`
- All diffusion parameters, codec settings, finalizer settings, etc.

Mechanical parameters in tasq.md are **ignored with a warning**.

---

## Post-Stitch Finalizer Config

```yaml
finalizer:
  enabled: true                    # Set to false to skip post-stitch processing
  interpolate_fps: 60              # Target frame rate
  upscale_resolution: 1920x1080   # Target resolution
  scale_algo: bicubic              # Scaling algorithm
  encoder_preference:              # GPU-first with CPU fallback
    - h264_nvenc
    - libx264
  quality:
    crf: 16                        # CRF / NVENC CQ value (lower = better)
```

---

## Backend Options

| Backend | Availability | Setup |
|---------|-------------|-------|
| `mock` | âœ… Always | None needed |
| `comfyui` | âœ… Works | ComfyUI server + SDXL/SVD checkpoints |
| `diffusers` | âš ï¸ Needs CUDA | `pip install torch diffusers` |
| `replicate` | âš ï¸ Needs token | `REPLICATE_API_TOKEN` env var |

ComfyUI validates SDXL and SVD checkpoint availability via `/object_info` before generating. NVENC encoding is preferred; libx264 is automatic fallback.

---

## Known Limitations (v0.3.5-beta)

- Video mode does frame extraction (not true video2video via AnimateDiff)
- ComfyUI needs VideoHelperSuite nodes for video output
- Diffusers backend requires CUDA (no CPU fallback)
- LLM evolution is optional (basic fallback always works)
- Post-stitch interpolation (minterpolate) is CPU-intensive and can be slow for long videos
- Default SVD workflow ignores text prompts (motion_prompt.md stored for auditability but not used by SVD directly)
- Split backends share the same project directory (no per-backend output isolation)

---

## License

Visual FaQtory is licensed under the GNU Affero General Public License v3.0 (AGPL-3.0).
See the [LICENSE](LICENSE) file for full text.

---

Built by **Ill Dynamics / WoNQ** for the drum & bass massive ğŸµ

```
â–‘â–’â–“â–ˆ ONE LOVE â–ˆâ–“â–’â–‘
```

![Scarf](https://static.scarf.sh/a.png?x-pxid=dc67438c-3388-46cd-baa7-7a0374420474)
